0.000413177	,
0.000512233	,
0.000503956	,
0.000509294	,
-0.000490594	,
-0.000314761	,
0.00043515	,
-0.000401275	,
-0.00039775	,
-1.31E-06	,
0.000256757	,
0.00042835	,
-0.000322324	,
-0.000381926	,
-2.22E-05	,
0.000339289	,
0.000386716	,
0.000349806	,
0.00020518	,
-0.000368699	,
0.000226529	,
-0.000259628	,
-0.000325298	,
-3.38E-05	,
-0.000270048	,
-0.000165764	,
-0.00025901	,
0.000121174	,
0.000238534	,
-0.000225101	,
-0.000190917	,
0.000203268	,
8.85E-05	,
0.000214436	,
-0.000220251	,
-2.99E-05	,
0.000185123	,
-0.00020343	,
0.000132832	,
-0.000153243	,
0.000165188	,
-0.000186548	,
0.000169187	,
8.79E-05	,
0.00011287	,
-0.000141364	,
0.000148883	,
-0.000151794	,
-6.48E-05	,
-6.51E-06	,
-0.000149167	,
9.27E-05	,
0.000128419	,
0.000119798	,
-0.00013105	,
-0.00010973	,
3.92E-05	,
0.000101336
)
hist(x[1:30], xlab = "Amplitude B BAT data", main = "")
lines(density(x[1:30]), col = "green")
hist(rpois(1000, lambda = 10))
hist(rpois(1000, lambda = 20))
hist(rpois(10000, lambda = 20))
hist(rpois(10000, lambda = 100))
install.packages("invgamma", dependencies = T)
library(invgamma)
hist(rinvgamma(1e4, shape = 1))
hist(rinvgamma(1e4, shape = 0))
hist(rinvgamma(1e4, shape = 0.1, scale = 1))
hist(rinvgamma(1e2, shape = 0.1, scale = 1))
hist(rinvgamma(1e2, shape = 0.1, scale = .1))
hist(rinvgamma(1e2, shape = 0.1, scale = 10))
hist(rinvgamma(1e2, shape = 0, scale = 10))
hist(rinvgamma(1e2, shape = 1, scale = 10))
hist(rinvgamma(1e5, shape = 1, scale = 10))
hist(rinvgamma(1e2, shape = 2, scale = 10))
hist(rinvgamma(1e2, shape = 2, scale = 1))
hist(rinvgamma(1e2, shape = 20, scale = 1))
hist(rinvgamma(1e2, shape = 20, scale = 100))
hist(rinvgamma(1e2, shape = 20, scale = 1))
hist(rinvgamma(1e2, shape = 0.0, scale = 1))
hist(rinvgamma(1e2, shape = .20, scale = 1))
hist(rinvgamma(1e5, shape = .20, scale = 1))
hist(rinvgamma(1e3, shape = 1, scale = 10))
hist(rinvgamma(1e3, shape = 1, scale = 1))
hist(rinvgamma(1e3, shape = .1, scale = 1))
hist(rinvgamma(1e3, shape = 100, scale = 1))
hist(rinvgamma(1e3, shape = 100, scale = 0.01))
grad_lad <- function(sg,y,x, tau = 0.5){
(tau - as.numeric( y - t(x) %*% sg < 0 )) %*% x
}
st <- Sys.time()
max_sam = 1e5
Rep = 10
nparm = 20
cns = c(0.1, 1)
ncores_par = 1
eta_cns = 1
sam_siz = 1e5
qlev = 0.95
burn_in = 10000
sam_siz <- sam_siz[sam_siz <= max_sam]
n <- sam_siz[length(sam_siz)]
parm <- seq(1 / nparm, 1, length.out = nparm)
sg <- matrix(nrow = n + burn_in, ncol = nparm);
sg_ct <- matrix(nrow = n , ncol = nparm)
#Iterates stored
mse <- matrix(rep(0, 4*nparm ), nrow = 4, ncol = nparm)
for( k in 1 : Rep)
{x <- matrix(rnorm((n + burn_in) * nparm), nrow = (n + burn_in), ncol = nparm)
#noisy Observed Data
y <- x %*% parm + rdoublex(n + burn_in, mu = 0,lambda = 1)
#Learning Rate
eta <- numeric(n + burn_in)
sg[1,] <- rep(0, nparm)
alp = 0.51
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[1, ] <-  mse[1, ] + (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 2/3
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[2,  ] <- mse[2, ] +  (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.75
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[3,  ] <- mse[3, ] +   (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.95
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[4,  ] <- mse[4, ] +  (colMeans(sg_ct_full)-parm)^2
}
mse <- mse/Rep
print(mse)
print(difftime(Sys.time(), st, units = "secs"))
setwd("C:/Users/Hp/Documents/GitHub/Batch_Means_Online/linear_lad")
grad_lad <- function(sg,y,x, tau = 0.5){
(tau - as.numeric( y - t(x) %*% sg < 0 )) %*% x
}
st <- Sys.time()
max_sam = 1e5
Rep = 10
nparm = 20
cns = c(0.1, 1)
ncores_par = 1
eta_cns = 1
sam_siz = 1e5
qlev = 0.95
burn_in = 10000
sam_siz <- sam_siz[sam_siz <= max_sam]
n <- sam_siz[length(sam_siz)]
parm <- seq(1 / nparm, 1, length.out = nparm)
sg <- matrix(nrow = n + burn_in, ncol = nparm);
sg_ct <- matrix(nrow = n , ncol = nparm)
#Iterates stored
mse <- matrix(rep(0, 4*nparm ), nrow = 4, ncol = nparm)
for( k in 1 : Rep)
{x <- matrix(rnorm((n + burn_in) * nparm), nrow = (n + burn_in), ncol = nparm)
#noisy Observed Data
y <- x %*% parm + rdoublex(n + burn_in, mu = 0,lambda = 1)
#Learning Rate
eta <- numeric(n + burn_in)
sg[1,] <- rep(0, nparm)
alp = 0.51
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[1, ] <-  mse[1, ] + (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 2/3
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[2,  ] <- mse[2, ] +  (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.75
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[3,  ] <- mse[3, ] +   (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.95
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[4,  ] <- mse[4, ] +  (colMeans(sg_ct_full)-parm)^2
}
mse <- mse/Rep
print(mse)
print(difftime(Sys.time(), st, units = "secs"))
library(smoothmest)
grad_lad <- function(sg,y,x, tau = 0.5){
(tau - as.numeric( y - t(x) %*% sg < 0 )) %*% x
}
st <- Sys.time()
max_sam = 1e5
Rep = 10
nparm = 20
cns = c(0.1, 1)
ncores_par = 1
eta_cns = 1
sam_siz = 1e5
qlev = 0.95
burn_in = 10000
sam_siz <- sam_siz[sam_siz <= max_sam]
n <- sam_siz[length(sam_siz)]
parm <- seq(1 / nparm, 1, length.out = nparm)
sg <- matrix(nrow = n + burn_in, ncol = nparm);
sg_ct <- matrix(nrow = n , ncol = nparm)
#Iterates stored
mse <- matrix(rep(0, 4*nparm ), nrow = 4, ncol = nparm)
for( k in 1 : Rep)
{x <- matrix(rnorm((n + burn_in) * nparm), nrow = (n + burn_in), ncol = nparm)
#noisy Observed Data
y <- x %*% parm + rdoublex(n + burn_in, mu = 0,lambda = 1)
#Learning Rate
eta <- numeric(n + burn_in)
sg[1,] <- rep(0, nparm)
alp = 0.51
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[1, ] <-  mse[1, ] + (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 2/3
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[2,  ] <- mse[2, ] +  (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.75
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[3,  ] <- mse[3, ] +   (colMeans(sg_ct_full)-parm)^2
sg[1,] <- rep(0, nparm)
alp = 0.95
for(i in 2 : (n + burn_in)){
eta[i] <- i^( - alp)
sg[i,] <- sg[i - 1,] + eta_cns * eta[i] * grad_lad(sg[i - 1,], y[i], x[i,])
}
sg_ct_full <- sg[(burn_in + 1) : (n + burn_in),]
mse[4,  ] <- mse[4, ] +  (colMeans(sg_ct_full)-parm)^2
}
mse <- mse/Rep
print(mse)
print(difftime(Sys.time(), st, units = "secs"))
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("./../opt_bet_fn.R")
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
linear_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
r <- 0.5
toep_mat <- equiv_mat <- matrix(nrow = nparm, ncol = nparm)
for( i in 1 : nparm){
for(j in 1 : nparm){
toep_mat[i,j] <- r^(abs(i-j))
if(i == j ){
equiv_mat[i, j] <- 1
}else{
equiv_mat[i, j] <- r
}
}
}
linear_batch_fn(max_sam = max_sam, A = toep_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "toep")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
linear_batch_fn(max_sam = max_sam, A = equiv_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "equiv")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("./../opt_bet_fn.R")
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
r <- 0.5
toep_mat <- equiv_mat <- matrix(nrow = nparm, ncol = nparm)
for( i in 1 : nparm){
for(j in 1 : nparm){
toep_mat[i,j] <- r^(abs(i-j))
if(i == j ){
equiv_mat[i, j] <- 1
}else{
equiv_mat[i, j] <- r
}
}
}
linear_batch_fn(max_sam = max_sam, A = toep_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "toep")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
linear_batch_fn(max_sam = max_sam, A = equiv_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "equiv")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("./../opt_bet_fn.R")
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
r <- 0.5
toep_mat <- equiv_mat <- matrix(nrow = nparm, ncol = nparm)
for( i in 1 : nparm){
for(j in 1 : nparm){
toep_mat[i,j] <- r^(abs(i-j))
if(i == j ){
equiv_mat[i, j] <- 1
}else{
equiv_mat[i, j] <- r
}
}
}
linear_batch_fn(max_sam = max_sam, A = toep_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "toep")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
linear_batch_fn(max_sam = max_sam, A = equiv_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "equiv")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("./../opt_bet_fn.R")
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
r <- 0.5
toep_mat <- equiv_mat <- matrix(nrow = nparm, ncol = nparm)
for( i in 1 : nparm){
for(j in 1 : nparm){
toep_mat[i,j] <- r^(abs(i-j))
if(i == j ){
equiv_mat[i, j] <- 1
}else{
equiv_mat[i, j] <- r
}
}
}
linear_batch_fn(max_sam = max_sam, A = toep_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "toep")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
linear_batch_fn(max_sam = max_sam, A = equiv_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "equiv")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
r <- 0.5
toep_mat <- equiv_mat <- matrix(nrow = nparm, ncol = nparm)
for( i in 1 : nparm){
for(j in 1 : nparm){
toep_mat[i,j] <- r^(abs(i-j))
if(i == j ){
equiv_mat[i, j] <- 1
}else{
equiv_mat[i, j] <- r
}
}
}
linear_batch_fn(max_sam = max_sam, A = toep_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "toep")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
linear_batch_fn(max_sam = max_sam, A = equiv_mat, nparm = nparm, Rep = 30, ncores_par = 15, nam_matrix = "equiv")#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2, nam_matrix = "indep", cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
rm(list=ls())
set.seed(1)
library(MASS)
library(doParallel)
library(foreach)
library(mcmcse)
library(smoothmest)
source("grad_lad_and_batch.R")
source("./../ebs_batch_mean.R")
source("./../ibs_jasa_mean.R")
source("./../sqrt_mat.R")
max_sam <- 1e6
nparm <- 5
lad_batch_fn(max_sam = max_sam, nparm = nparm, Rep = 2, ncores_par = 2,  cns = c(0.1, 1))#max(detectCores() - 5, 1)
#foo <- paste("out/linear_", nam_matrix,"_n_",max_sam,"_dim_",nparm,".RData",sep="")
#load(foo)
load("~/GitHub/Batch_Means_Online/linear_lad/out/lad_n_1e+06_dim_5.RData")
cover_ibs
cover_ebs
cover_ebs_ls
load("~/GitHub/Batch_Means_Online/linear_lad/lad_n_1e+06_dim_20.RData")
cover_ebs
cover_ebs_ls
load("~/GitHub/Batch_Means_Online/linear_lad/out/lad_n_1e+06_dim_20.RData")
cover_ebs_ls
cover_ibs
load("~/GitHub/Batch_Means_Online/linear_lad/out/lad_n_1e+06_dim_20.RData")
cover_ibs
cover_ebs_ls
load("~/GitHub/Batch_Means_Online/linear_lad/out/lad_n_1e+06_dim_20.RData")
cover_ebs_ls
cover_ebs
